{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "import numpy.polynomial.polynomial as poly\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"xML Challenge Dataset and Data Dictionary/heloc_dataset_v1_pure.csv\")\n",
    "feature_names = list(df)\n",
    "data = df.values\n",
    "\n",
    "y_original= data[:,:1]\n",
    "X_original = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Basic Functions for Matrix editing --- \n",
    "\n",
    "def remove_row_with_all_same_val(data, target, val):\n",
    "    row_no = 0 \n",
    "    for row in data:\n",
    "        for col in row:\n",
    "            if (col == val):\n",
    "                remove = True\n",
    "            else:\n",
    "                remove = False\n",
    "                break\n",
    "\n",
    "        if remove:\n",
    "            data = np.delete(data, row_no, 0)\n",
    "            target = np.delete(target, row_no, 0)     \n",
    "\n",
    "        else:\n",
    "            row_no += 1\n",
    "    return data,target\n",
    "\n",
    "\n",
    "def remove_row_with_vals(data, target, vals):\n",
    "    row_no = 0 \n",
    "    for row in data:\n",
    "        for col in row:\n",
    "            if (col in vals):\n",
    "                data = np.delete(data, row_no, 0)\n",
    "                target = np.delete(target, row_no, 0) \n",
    "                row_no -= 1\n",
    "                break\n",
    "        row_no += 1\n",
    "    return data,target\n",
    "\n",
    "\n",
    "def remove_col_with_vals(data, vals):\n",
    "    no_cols = data.shape[1]\n",
    "    no_rows = data.shape[0]\n",
    "    row = 0\n",
    "    while (no_rows > row):\n",
    "        col = 0\n",
    "        while (no_cols > col):\n",
    "            if (data[row][col] in vals):\n",
    "                data = np.delete(data, col, 1)\n",
    "                no_cols -= 1\n",
    "            else:\n",
    "                col += 1\n",
    "        row += 1     \n",
    "    return data\n",
    "\n",
    "\n",
    "def scaled_row(row):\n",
    "    scld = []\n",
    "    for k in range(features):\n",
    "        scld.append((row[k] - scaler.mean_[k])/scaler.scale_[k])\n",
    "    scld = np.array(scld)\n",
    "    return scld\n",
    "        \n",
    "        \n",
    "def masked_arr(A, mask):\n",
    "    B = []\n",
    "    for i in range(len(A)):\n",
    "        row = []\n",
    "        for j in range(len(A[0])):\n",
    "            if mask[j] != 0:\n",
    "                row.append(A[i][j])\n",
    "        B.append(row)\n",
    "    B = np.array(B)\n",
    "    return B\n",
    "\n",
    "\n",
    "def distance(row1, row2):\n",
    "    dist = 0\n",
    "    for i in range(len(row1)):\n",
    "        t = (row1[i]-row2[i])**2\n",
    "        dist += t\n",
    "    dist = np.sqrt(dist)\n",
    "    return dist\n",
    "\n",
    "# predict features using kNN imputation\n",
    "# need to test for both weighted and simple mean\n",
    "# using 3 or 5 neighbors\n",
    "def predict_feature_weighted(row, C, k, originalArr, ft_idx):\n",
    "    \n",
    "    distances = []\n",
    "    for i in range(len(C)):\n",
    "        distances.append(distance(row,C[i]))\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    max_dist = np.max(distances)\n",
    "        \n",
    "    idx = np.argpartition(distances, k)\n",
    "\n",
    "    values = []\n",
    "    min_dists = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        values.append(originalArr[idx[i]][ft_idx])\n",
    "#         print(Z[idx[i]])\n",
    "        min_dists.append(distances[idx[i]])\n",
    "    values = np.array(values) \n",
    "    min_dists = np.array(min_dists)\n",
    "\n",
    "    weights = []\n",
    "    for i in min_dists:\n",
    "        weights.append(1 - (i/max_dist))\n",
    "        \n",
    "    imputed_val = 0\n",
    "    for i in range(len(weights)):\n",
    "        imputed_val += weights[i] * values[i]\n",
    "        \n",
    "    return imputed_val    \n",
    "\n",
    "\n",
    "def predict_feature_mean(row, C, k, originalArr, ft_idx):\n",
    "    \n",
    "    distances = []\n",
    "    for i in range(len(C)):\n",
    "        distances.append(distance(row,C[i]))\n",
    "    distances = np.array(distances)\n",
    "        \n",
    "    idx = np.argpartition(distances, k)\n",
    "    \n",
    "    values = []\n",
    "    min_dists = []\n",
    "    for i in range(k):\n",
    "        values.append(originalArr[idx[i]][ft_idx])\n",
    "#         print(Z[idx[i]])\n",
    "        min_dists.append(distances[idx[i]])\n",
    "    values = np.array(values) \n",
    "    min_dists = np.array(min_dists)\n",
    "        \n",
    "    imputed_val = 0\n",
    "    for i in range(len(values)):\n",
    "        imputed_val += values[i]/(len(values))\n",
    "        \n",
    "    return imputed_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10459, 23)\n",
      "(9871, 23)\n",
      "(10459, 1)\n",
      "(9871, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Removing the rows with only -9 values ---\n",
    "X, y = remove_row_with_all_same_val(X_original,y_original,-9)\n",
    "\n",
    "# --- Testing ---\n",
    "print(X_original.shape)\n",
    "print(X.shape)\n",
    "print(y_original.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Taking the array without any negatives present ---\n",
    "\n",
    "samples, features = X.shape\n",
    "\n",
    "X_good = []\n",
    "\n",
    "for i in range(samples):\n",
    "    remove = False\n",
    "    for j in range(features):\n",
    "        if X[i][j] < 0:\n",
    "            remove = True\n",
    "            break\n",
    "    if remove == False:\n",
    "        X_good.append(X[i])\n",
    "        \n",
    "X_good = np.array(X_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steffen/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "14\n",
      "\n",
      "\n",
      "17\n",
      "\n",
      "\n",
      "18\n",
      "\n",
      "\n",
      "19\n",
      "\n",
      "\n",
      "20\n",
      "\n",
      "\n",
      "21\n",
      "\n",
      "\n",
      "22\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Replacing -8 with k-nearest neighbours (average) ---\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_good_std = scaler.fit_transform(X_good)\n",
    "\n",
    "X_no_8 = np.copy(X)\n",
    "\n",
    "kNN = 5\n",
    "\n",
    "cols_with_8 = [1,8,14,17,18,19,20,21,22]\n",
    "\n",
    "for q in cols_with_8:\n",
    "\n",
    "    print(q)\n",
    "    \n",
    "    for i in range(samples):\n",
    "\n",
    "        if X[i][q] == -8:\n",
    "\n",
    "            row_to_comp = []\n",
    "            mask = []\n",
    "            scaled = scaled_row(X[i])\n",
    "            for j in range(features):\n",
    "                if X[i][j] >= 0:\n",
    "                    mask.append(1)\n",
    "                    row_to_comp.append(scaled[j])\n",
    "                else:\n",
    "                    mask.append(0)\n",
    "            row_to_comp = np.array(row_to_comp)\n",
    "            mask = np.array(mask)\n",
    "\n",
    "            S = masked_arr(X_good_std, mask)\n",
    "\n",
    "            imputed = predict_feature_mean(row_to_comp, S, k, X_good_std, q)\n",
    "\n",
    "            X_no_8[i][q] = imputed*scaler.scale_[q] + scaler.mean_[q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55]\n",
      " [61]\n",
      " [67]\n",
      " ..., \n",
      " [74]\n",
      " [72]\n",
      " [66]]\n"
     ]
    }
   ],
   "source": [
    "# --- Selecting the column with -9  ---\n",
    "y_nine = X_no_8[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Selecting the columns with -7  ---\n",
    "X_no8 = np.copy(imputed_8_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # --- Removing the columns that have -8 values ---\n",
    "# X2 = remove_col_with_vals(X,[-8])\n",
    "\n",
    "# # --- Testing ---\n",
    "# print(X.shape)\n",
    "# print(X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_degrees(X_tr,y_tr,degrees):\n",
    "    RSS_list = []\n",
    "    for deg in degrees:\n",
    "        model = poly.polyfit(X_tr,y_tr,degree)\n",
    "        pred = poly.polyval(X_tr, model)\n",
    "        RSS = np.mean((Y_tr-pred)**2)\n",
    "        RSS_list.append(RSS)\n",
    "        \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(degrees,RSS_list,'.-',color='r') \n",
    "    plt.xlabel('Degree')                            \n",
    "    plt.ylabel('Performance')\n",
    "    \n",
    "\n",
    "def predict_values_poly_reg(X_tr,y_tr,X_test,deg):\n",
    "    model = poly.polyfit(X_tr,y_tr,degree)\n",
    "    pred = poly.polyval(X_test, model)\n",
    "    return pred\n",
    "\n",
    "def predict_values_lin_reg(X_tr,y_tr,X_test):\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    pred = model.predict(X_test)\n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Shift categorical features so they match  ---\n",
    "\n",
    "# Assumes array without labels where MaxDelq2PublicRecLast12M is in [9] and MaxDelqEver is in [10]\n",
    "\n",
    "# [9]:\n",
    "#     5,6 -> 6\n",
    "#     7 -> 5\n",
    "#     8,9 ->7\n",
    "\n",
    "# [10]:\n",
    "#     1-> 7\n",
    "#     2 -> 0\n",
    "#     3 -> 1\n",
    "#     4 -> 2\n",
    "#     5 -> 3\n",
    "#     6 -> 4\n",
    "#     7 -> 6\n",
    "#     8 -> 5\n",
    "#     9 -> 7\n",
    "\n",
    "def shift_categorical (X):\n",
    "    \n",
    "    new_9 = []\n",
    "    for i in X[9]:\n",
    "        if i == 5:\n",
    "            new_9.append(6)\n",
    "        elif i == 7:\n",
    "            new_9.append(5)\n",
    "        elif i in [8,9]:\n",
    "            new_9.append(7)\n",
    "            \n",
    "    new_10 = []\n",
    "    for i in X[10]:\n",
    "        if i == 1:\n",
    "            new_10.append(7)\n",
    "        elif i in [2,3,4,5,6,9]:\n",
    "            new_10.append(i-2)\n",
    "        elif i == 7:\n",
    "            new_10.append(6)\n",
    "        elif i == 8:\n",
    "            new_10.append(5)\n",
    "            \n",
    "    X_shifted = np.copy(X)\n",
    "    \n",
    "    for i in range(len(X[0])):\n",
    "        X_shifted[9][i] = new_9[i]\n",
    "        X_shifted[10][i] = new_10[i]\n",
    "        \n",
    "    return X_shifted"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
