{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -- Imports -- \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from SVM_model import SVM_model\n",
    "from Functions import separate_bins_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 72.67 %\n",
      "Test Accuracy: 74.73 %\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"working_data_full.csv\")\n",
    "vals = df.values\n",
    "X = vals[:,2:]\n",
    "y = vals[:,1]\n",
    "\n",
    "no_samples, no_features = X.shape\n",
    "\n",
    "svm_model = SVM_model(None,\"working_data_full.csv\")\n",
    "svm_model.train_model(0.001)\n",
    "svm_model.test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def divide_data_bins(data, special=[]):\n",
    "    no_feat = data.shape[1]\n",
    "    bins_centred = []\n",
    "    X_pos_array = []\n",
    "    in_vals = []\n",
    "    \n",
    "    for i in range(no_feat):\n",
    "        # Handles special case\n",
    "        bins, new_col, val = separate_bins_feature(X[:,i].flatten(),(i in special))[:3]\n",
    "        \n",
    "        in_vals.append(val)\n",
    "        bins_centred.append(bins)\n",
    "        X_pos_array.append(new_col)\n",
    "        \n",
    "    # Convert to numpy array\n",
    "    in_vals = np.array(in_vals).transpose()\n",
    "    bins_centred = np.array(bins_centred)\n",
    "    X_pos_array = (np.array(X_pos_array)).transpose() \n",
    "\n",
    "    return bins_centred, X_pos_array, in_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  58.  101.   28.  134.    2.    3.    2.   71.   10.    1.    4.    6.\n",
      "    0.    3.    7.    3.    3.   76.   59.    3.    2.    0.   90.]\n",
      "[[  54.   58.   62.   66.   70.   74.   78.   82.   86.   90.]\n",
      " [  25.   63.  101.  139.  177.  215.  253.  291.  329.  367.]\n",
      " [   1.    4.    7.   10.   13.   16.   19.   22.   25.   28.]\n",
      " [  17.   30.   43.   56.   69.   82.   95.  108.  121.  134.]\n",
      " [   2.    6.   10.   14.   18.   22.   26.   30.   34.   38.]\n",
      " [   0.    1.    2.    3.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [   0.    1.    2.   -1.   -1.   -1.   -1.   -1.   -1.   -1.]\n",
      " [  71.   75.   79.   83.   87.   91.   95.   99.  103.  107.]\n",
      " [  10.   31.   52.   73.   94.  115.  136.  157.  178.  199.]\n",
      " [   0.    1.    2.    3.    4.    5.    6.    7.   -1.   -1.]\n",
      " [   0.    1.    2.    3.    4.    5.    6.    7.   -1.   -1.]\n",
      " [   2.    6.   10.   14.   18.   22.   26.   30.   34.   38.]\n",
      " [   0.    1.    2.    3.    4.    5.    6.   -1.   -1.   -1.]\n",
      " [   3.   10.   17.   24.   31.   38.   45.   52.   59.   66.]\n",
      " [   7.   21.   35.   49.   63.   77.   91.  105.  119.  133.]\n",
      " [   0.    1.    2.    3.    4.    5.    6.   -1.   -1.   -1.]\n",
      " [   0.    1.    2.    3.    4.    5.    6.   -1.   -1.   -1.]\n",
      " [   4.   13.   22.   31.   40.   49.   58.   67.   76.   85.]\n",
      " [  27.   35.   43.   51.   59.   67.   75.   83.   91.   99.]\n",
      " [   0.    1.    2.    3.    4.    5.    6.    7.    8.    9.]\n",
      " [   0.    1.    2.    3.    4.    5.    6.   -1.   -1.   -1.]\n",
      " [   0.    1.    2.    3.    4.   -1.   -1.   -1.   -1.   -1.]\n",
      " [  26.   34.   42.   50.   58.   66.   74.   82.   90.   98.]]\n",
      "[ 1.  2.  9.  9.  0.  3.  2.  0.  0.  1.  4.  1.  0.  0.  0.  3.  3.  8.\n",
      "  4.  3.  2.  0.  8.]\n"
     ]
    }
   ],
   "source": [
    "bins_centred, X_pos_array, in_vals = divide_data_bins(X,[9,10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_data_set(data):\n",
    "    no_features = data.shape[1]\n",
    "    avg_list = []\n",
    "    std_list = []\n",
    "    for i in range(no_features):\n",
    "        current_col = data[:,i].flatten()\n",
    "        std_list.append(np.std(current_col))\n",
    "        avg_list.append(np.mean(current_col))\n",
    "          \n",
    "    return avg_list, std_list\n",
    "\n",
    "\n",
    "def perturb_special(min_val,max_val,avg,std,no_val):\n",
    "    new_col = np.random.normal(avg, std, no_val)\n",
    "    # Note: these functions have poor time complexity\n",
    "    np.place(new_col,new_col < min_val, min_val)\n",
    "    np.place(new_col,new_col > max_val, max_val)\n",
    "    new_col = new_col.round(0)\n",
    "    return new_col\n",
    "    \n",
    "\n",
    "def find_anchors(model, data_set, sample, no_val):\n",
    "    # Account for the special categorical columns\n",
    "    special_cols = [9,10]\n",
    "    \n",
    "    features = sample.shape[0]\n",
    "    avg_list, std_list = evaluate_data_set(data_set)\n",
    "\n",
    "    # Precision Treshold\n",
    "    treshold = 0.95\n",
    "    \n",
    "    # Identify original result from sample\n",
    "    initial_percentage = model.run_model(sample)\n",
    "    decision = np.round(initial_percentage,0)\n",
    "\n",
    "    # Create empty mask \n",
    "    mask = np.zeros(features)\n",
    "    \n",
    "    # Allows tracking the path\n",
    "    locked = []\n",
    "    \n",
    "    # Iterations allowed\n",
    "    iterations = 4\n",
    "    \n",
    "    while (iterations > 0):\n",
    "        # Retains best result and the corresponding index\n",
    "        max_ind = (0,0)\n",
    "    \n",
    "        # Assign column that is being tested\n",
    "        for test_col in range(features):\n",
    "            new_data = np.empty([features, no_val])\n",
    "\n",
    "            # Perturb data\n",
    "            for ind in range(features):\n",
    "                if (ind == test_col) or (ind in locked):\n",
    "                    new_data[ind] = np.array(np.repeat(sample[ind],no_val))\n",
    "                else:\n",
    "                    if (ind in special_cols):\n",
    "                        new_data[ind] = perturb_special(0,7,avg_list[ind],std_list[ind],no_val)\n",
    "                    else:\n",
    "                        new_data[ind] = np.random.normal(avg_list[ind], std_list[ind], no_val)\n",
    "            \n",
    "            new_data = new_data.transpose()\n",
    "\n",
    "            # Run Model \n",
    "            pred = model.run_model_data(new_data)\n",
    "            acc = (np.mean(pred == decision))\n",
    "            \n",
    "            if (acc > max_ind[0]):\n",
    "                max_ind = (acc,test_col)\n",
    "                \n",
    "\n",
    "        locked.append(max_ind[1])\n",
    "            \n",
    "        for n in locked:\n",
    "            mask[n] = 1\n",
    "            \n",
    "        if (max_ind[0] >= treshold):\n",
    "            return mask\n",
    "        iterations -= 1\n",
    "        \n",
    "    print(\"!!! No anchors found !!!\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def perturb_row_feature(model, row, row_idx, feat_idx, current_bins, X_bin_pos, mean_bins, mono_arr, improve):\n",
    "    \n",
    "    monot_arr = np.copy(mono_arr)                        \n",
    "    \n",
    "    c_current_bins = np.copy(current_bins)\n",
    "    direction = monot_arr[feat_idx]\n",
    "    current_bin = np.copy(c_current_bins[feat_idx])\n",
    "    \n",
    "    if current_bin != 9:\n",
    "        next_value = mean_bins[feat_idx][int(current_bin+1)]\n",
    "    if current_bin != 0:\n",
    "        prev_value = mean_bins[feat_idx][int(X_bin_pos[row_idx][feat_idx]-1)]\n",
    "    \n",
    "    # Check if in boundary and return the same row\n",
    "    if direction == -1:\n",
    "        if current_bin == 0:\n",
    "            direction = 1\n",
    "        elif current_bin == 9 or next_value == -1:\n",
    "            direction = 0\n",
    "    if direction == 1:\n",
    "        if current_bin == 9 or next_value == -1:\n",
    "            return (row, c_current_bins)\n",
    "    elif direction == 0 and current_bin ==  0:\n",
    "            return (row, c_current_bins)\n",
    "    \n",
    "    # Decide direction in special case\n",
    "    if direction == -1:\n",
    "        row_up = np.copy(row)\n",
    "        row_down = np.copy(row)\n",
    "        row_up[feat_idx] = next_value\n",
    "        row_down[feat_idx] = prev_value\n",
    "        percent_1 = model.run_model(row_up)\n",
    "        percent_0 = model.run_model(row_down)\n",
    "        if percent_1 >= percent_0:\n",
    "            if improve:\n",
    "                c_current_bins[feat_idx] += 1\n",
    "                return (row_up, c_current_bins)\n",
    "            else:\n",
    "                c_current_bins[feat_idx] -= 1\n",
    "                return (row_down, c_current_bins)\n",
    "        elif not improve:\n",
    "            c_current_bins[feat_idx] -= 1\n",
    "            return (row_down, c_current_bins)\n",
    "        else:\n",
    "            c_current_bins[feat_idx] += 1\n",
    "            return (row_up, c_current_bins)\n",
    "        \n",
    "    else:\n",
    "        p_row = np.copy(row)\n",
    "        if direction == 1:\n",
    "            c_current_bins[feat_idx] += 1\n",
    "            p_row[feat_idx] = next_value\n",
    "        elif direction == 0:\n",
    "            c_current_bins[feat_idx] -= 1\n",
    "            p_row[feat_idx] = prev_value\n",
    "        \n",
    "        return (p_row, c_current_bins)\n",
    "    \n",
    "    \n",
    "def percent_cond (improve, percent):\n",
    "    if improve and percent <= 0.5:\n",
    "        return True\n",
    "    elif (not improve) and percent > 0.5:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def find_MSC (model, data, k_row, row_idx, X_bin_pos, mean_bins):\n",
    "    \n",
    "    row = np.copy(k_row)\n",
    "    percent = model.run_model(row)\n",
    "    features_moved = np.zeros(23)\n",
    "    times_moved = np.zeros(23)\n",
    "    change_vector = np.zeros(23)\n",
    "    \n",
    "    original_bins = np.copy(X_bin_pos[row_idx])\n",
    "    current_bins = np.copy(X_bin_pos[row_idx])\n",
    "    \n",
    "    # Decides class to change into\n",
    "    improve = True\n",
    "    if percent >= .5:\n",
    "        improve = False\n",
    "        \n",
    "    # Hardcodes the constraints for the direction in which to move\n",
    "    # 1: Move up to to improve\n",
    "    # 0: Move down to improve\n",
    "    # -1: Needs check\n",
    "    monotonicity_arr = np.array([1,1,1,1,1,0,0,1,1,1,1,-1,0,-1,1,0,0,0,0,-1,-1,0,-1])\n",
    "    monotonicity_arr_c = np.copy(monotonicity_arr)\n",
    "    if not improve:\n",
    "        for i in range(len(monotonicity_arr)):\n",
    "            if monotonicity_arr[i] == 1:\n",
    "                monotonicity_arr_c[i] = 0\n",
    "            elif monotonicity_arr[i] == 0:\n",
    "                monotonicity_arr_c[i] = 1\n",
    "    monotonicity_arr = np.copy(monotonicity_arr_c)\n",
    "    \n",
    "    while percent_cond(improve, percent) and (features_moved == 1).sum() < 5 and max(times_moved) < 5:\n",
    "        new_percents = []\n",
    "        pert_rows = []\n",
    "        new_curr_bins = []\n",
    "        \n",
    "        # Avoids moving ExternalScore\n",
    "        for i in range(1,len(row)):\n",
    "            t_row, t_current_bins = perturb_row_feature(model, row, row_idx, i, current_bins, X_bin_pos, mean_bins, monotonicity_arr, improve)\n",
    "            pert_rows.append(t_row)\n",
    "            new_curr_bins.append(t_current_bins)\n",
    "            new_percents.append(model.run_model(t_row))\n",
    "\n",
    "        new_percents = np.array(new_percents)\n",
    "        \n",
    "        if improve:\n",
    "            idx = np.argmax(new_percents)\n",
    "        else:\n",
    "            idx = np.argmin(new_percents)\n",
    "        \n",
    "        row = pert_rows[idx]\n",
    "        percent = new_percents[idx]\n",
    "        current_bins = new_curr_bins[idx]\n",
    "\n",
    "        features_moved[idx] = 1\n",
    "        times_moved[idx] += 1\n",
    "    \n",
    "    for l in range(23):\n",
    "        change_vector[l] = current_bins[l] - original_bins[l]\n",
    "        \n",
    "    if not percent_cond(improve, percent):\n",
    "        return change_vector, row\n",
    "    else:\n",
    "        print(\"Decision can't be moved within thresholds:\")\n",
    "        return None,None\n",
    "\n",
    "def instance_explanation(model, data, k_row, row_idx, X_bin_pos, mean_bins):\n",
    "    \n",
    "    initial_percentage = model.run_model(k_row)\n",
    "#     print(\"Initial %\",initial_percentage)\n",
    "    \n",
    "#     print(\"Change vector: \")\n",
    "    change_vector, change_row = find_MSC(model, data, k_row, row_idx, X_bin_pos, mean_bins)\n",
    "    anchors = find_anchors(model, data, k_row, 100)\n",
    "\n",
    "    return change_vector, change_row, anchors, initial_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "change_vector, change_row, anchors, percent = instance_explanation(svm_model, X, X[i], i, X_pos_array, bins_centred)\n",
    "\n",
    "print(change_vector)\n",
    "print(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_pos_array)\n",
    "print(bins_centred)\n",
    "def export_to_D3(row, in_vals, bins_centred, X_pos_array, change_row, anchors, percent):\n",
    "    data = []\n",
    "    \n",
    "    names = [\"External Risk Estimate\",\"Months Since Oldest Trade Open\",\"Months Since Last Trade Open\"\n",
    "             ,\"Average Months in File\",\"Satisfactory Trades\",\"Trades 60+ Ever\",\"Trades 90+ Ever\"\n",
    "            ,\"% Trades Never Delq.\",\"Months Since Last Delq.\",\"Max Delq. Last 12M\",\"Max Delq. Ever\",\"Total Trades\"\n",
    "             ,\"Trades Open Last 12M\",\"% Installment Trades\", \"Months Since Most Recent Inq\",\"Inq Last 6 Months\"\n",
    "             ,\"Inq Last 6 Months exl. 7 days\", \"Revolving Burden\",\"Installment Burden\",\"Revolving Trades w/ Balance\"\n",
    "            ,\"Installment Trades w/ Balance\",\"Bank Trades w/ High Utilization Ratio\",\"% trades with balance\"]\n",
    "    \n",
    "    for i in range(bins_centred.shape[0]):\n",
    "        print(X_pos_array[row][i])\n",
    "        result = {}\n",
    "        result[\"name\"] = names[i]\n",
    "        if (percent > 0.5):\n",
    "            result[\"dir\"] = 1\n",
    "        else:\n",
    "            result[\"dir\"] = 0\n",
    "            \n",
    "        if (anchors[i] == 1):\n",
    "            result[\"anch\"] = 1\n",
    "        \n",
    "        val = bins_centred[i][X_pos_array[row][i]]\n",
    "        change = change_row[i]\n",
    "        \n",
    "        max_bin = np.max(bins_centred[i])\n",
    "        min_bin = np.min(bins_centred[i])\n",
    "        \n",
    "        scl_val = val/(max_bin-min_bin)\n",
    "        scl_change = change/(max_bin-min_bin)\n",
    "        \n",
    "        result[\"val\"] = val\n",
    "        result[\"scl_val\"] = scl_val\n",
    "        result[\"change\"] = change\n",
    "        result[\"scl_change\"] = scl_change\n",
    "        \n",
    "        print(\"val\",val)\n",
    "        print(\"scl_val\",scl_val)\n",
    "        print(\"change\",change)\n",
    "        print(\"scl_change\",scl_change)\n",
    "        \n",
    "        \n",
    "        data.append(result)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for i in range(15,50):\n",
    "#     print(instance_explanation(svm_model, X, X[i], i, X_pos_array, bins_centred)[0])\n",
    "#     print(\"\\n==================\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_to_D3(i, in_vals, bins_centred, X_pos_array, change_row, anchors, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
