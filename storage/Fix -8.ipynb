{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing -8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"xML Challenge Dataset and Data Dictionary/heloc_dataset_v1.csv\")\n",
    "feature_names = list(df)\n",
    "data = df.values\n",
    "\n",
    "y = data[:,:1]\n",
    "\n",
    "y = y.reshape((y.shape[0],))\n",
    "data = data[:,1:]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "# print(data)\n",
    "# print(data.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RiskPerformance', 'ExternalRiskEstimate', 'MSinceOldestTradeOpen', 'MSinceMostRecentTradeOpen', 'AverageMInFile', 'NumSatisfactoryTrades', 'NumTrades60Ever2DerogPubRec', 'NumTrades90Ever2DerogPubRec', 'PercentTradesNeverDelq', 'MSinceMostRecentDelq', 'MaxDelq2PublicRecLast12M', 'MaxDelqEver', 'NumTotalTrades', 'NumTradesOpeninLast12M', 'PercentInstallTrades', 'MSinceMostRecentInqexcl7days', 'NumInqLast6M', 'NumInqLast6Mexcl7days', 'NetFractionRevolvingBurden', 'NetFractionInstallBurden', 'NumRevolvingTradesWBalance', 'NumInstallTradesWBalance', 'NumBank2NatlTradesWHighUtilization', 'PercentTradesWBalance']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 144 4 ..., 1 1 69]\n",
      " [61 58 15 ..., -8 -8 0]\n",
      " [67 66 5 ..., 2 1 86]\n",
      " ..., \n",
      " [74 129 6 ..., -8 0 56]\n",
      " [72 234 12 ..., 1 0 38]\n",
      " [66 28 1 ..., 1 0 100]] (10459, 23)\n",
      "[[55 144 4 ..., 1 1 69]\n",
      " [61 58 15 ..., -8 -8 0]\n",
      " [67 66 5 ..., 2 1 86]\n",
      " ..., \n",
      " [74 129 6 ..., -8 0 56]\n",
      " [72 234 12 ..., 1 0 38]\n",
      " [66 28 1 ..., 1 0 100]] (9871, 23)\n"
     ]
    }
   ],
   "source": [
    "# Remove all completely empty rows (588)\n",
    "\n",
    "X = np.transpose(data)\n",
    "\n",
    "samples = X.shape[0]\n",
    "features = X.shape[1]\n",
    "\n",
    "print(X, X.shape)\n",
    "\n",
    "Y = []\n",
    "\n",
    "for i in range(samples):\n",
    "    remove = True\n",
    "    for j in range(features):\n",
    "        if X[i][j] != -9:\n",
    "            remove = False\n",
    "            break\n",
    "    if not remove:\n",
    "        Y.append(X[i])\n",
    "        \n",
    "Y = np.array(Y)\n",
    "print(Y, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66 169 1 ..., 4 3 91]\n",
      " [59 137 11 ..., 4 3 94]\n",
      " [54 88 7 ..., 7 2 100]\n",
      " ..., \n",
      " [76 353 2 ..., 2 0 80]\n",
      " [57 176 4 ..., 3 1 100]\n",
      " [65 147 39 ..., 2 1 80]] (2502, 23)\n"
     ]
    }
   ],
   "source": [
    "# Data where to look for similar instances (all non-negative values)\n",
    "\n",
    "samples = Y.shape[0]\n",
    "\n",
    "Z = []\n",
    "\n",
    "for i in range(samples):\n",
    "    remove = False\n",
    "    for j in range(features):\n",
    "        if Y[i][j] < 0:\n",
    "            remove = True\n",
    "            break\n",
    "    if remove == False:\n",
    "        Z.append(Y[i])\n",
    "        \n",
    "Z = np.array(Z)\n",
    "print(Z, Z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(Z)):\n",
    "    for j in range(len(Z[0])):\n",
    "        if Z[i][j] < 0:\n",
    "            print(Z[i])\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03828426 -0.39124088 -0.93039838 ...,  0.50698896  1.1496406\n",
      "   1.08058076]\n",
      " [-0.93229828 -0.7399746   0.6050259  ...,  0.50698896  1.1496406\n",
      "   1.2404097 ]\n",
      " [-1.57087972 -1.27397312 -0.00914381 ...,  2.23595721  0.48226223\n",
      "   1.56006758]\n",
      " ..., \n",
      " [ 1.23887863  1.61397805 -0.77685595 ..., -0.64565654 -0.85249451\n",
      "   0.49454132]\n",
      " [-1.18773086 -0.31495537 -0.4697711  ..., -0.06933379 -0.18511614\n",
      "   1.56006758]\n",
      " [-0.16600055 -0.63099531  4.90421388 ..., -0.64565654 -0.18511614\n",
      "   0.49454132]] (2502, 23)\n",
      "[  66.29976019  204.90047962    7.05955236   76.45723421   24.23261391\n",
      "    0.95883293    0.57873701   87.09192646   21.11630695    4.72022382\n",
      "    5.00719424   26.38888889    2.17226219   38.37529976    2.11830536\n",
      "    1.67306155    1.61111111   41.11510791   68.54236611    4.76139089\n",
      "    3.12030376    1.2773781    70.71742606]\n",
      "[  7.82985483  91.7605541    6.51285781  26.839197    11.20655959\n",
      "   1.48274916   1.16777762  10.83505533  20.70564857   1.59787987\n",
      "   1.41447786  12.61536074   1.84260301  15.28318608   4.25435225\n",
      "   2.14246438   2.09015536  27.63416404  23.56285715   3.13132177\n",
      "   1.73513886   1.49840037  18.77006755]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oscar\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Z_std = scaler.fit_transform(Z)\n",
    "\n",
    "print(Z_std, Z_std.shape)\n",
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSinceOldestTradeOpen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Months Since Oldest Trade Open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Monotonically Decreasing\n",
    "# Avg: 200.769\n",
    "# Stdved: 7.946\n",
    "# Min: 2\n",
    "# Max: 803\n",
    "# -7: 0\n",
    "# -8: 239\n",
    "# -9: 588\n",
    "# Data is centred in the range 160-240. \n",
    "# Slight positive correlation\n",
    "# Slightly more negative in special case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do similarity search for closest points ignoring the negative features.\n",
    "# Standardize each feature and use Euclidean distance.\n",
    "\n",
    "# Set a maximun radius for similarity and weight the values from each accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# returns the array for similiarity search without the columns with a 0 in mask\n",
    "\n",
    "def scaled_row(row):\n",
    "    scld = []\n",
    "    for k in range(features):\n",
    "        scld.append((row[k] - scaler.mean_[k])/scaler.scale_[k])\n",
    "    scld = np.array(scld)\n",
    "    return scld\n",
    "        \n",
    "        \n",
    "def masked_arr(A, mask):\n",
    "    B = []\n",
    "    for i in range(len(A)):\n",
    "        row = []\n",
    "        for j in range(len(A[0])):\n",
    "            if mask[j] != 0:\n",
    "                row.append(A[i][j])\n",
    "        B.append(row)\n",
    "    B = np.array(B)\n",
    "    return B\n",
    "\n",
    "def distance(row1, row2):\n",
    "    dist = 0\n",
    "    for i in range(len(row1)):\n",
    "        t = (row1[i]-row2[i])**2\n",
    "        dist += t\n",
    "    dist = np.sqrt(dist)\n",
    "    return dist\n",
    "\n",
    "# predict features using kNN imputation\n",
    "# need to test for both weighted and simple mean\n",
    "# using 3 or 5 neighbors\n",
    "def predict_feature_weighted(row, C, k, originalArr, ft_idx):\n",
    "    \n",
    "    distances = []\n",
    "    for i in range(len(C)):\n",
    "        distances.append(distance(row,C[i]))\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    max_dist = np.max(distances)\n",
    "        \n",
    "    idx = np.argpartition(distances, k)\n",
    "#     print(idx)\n",
    "    \n",
    "    values = []\n",
    "    min_dists = []\n",
    "    for i in range(k):\n",
    "        values.append(originalArr[idx[i]][ft_idx])\n",
    "#         print(Z[idx[i]])\n",
    "        min_dists.append(distances[idx[i]])\n",
    "    values = np.array(values) \n",
    "    min_dists = np.array(min_dists)\n",
    "    \n",
    "#     max_dist = np.max(min_dists)\n",
    "\n",
    "    weights = []\n",
    "    for i in min_dists:\n",
    "        weights.append(1 - (i/max_dist))\n",
    "    \n",
    "#     print(weights)\n",
    "#     print(values)\n",
    "        \n",
    "    imputed_val = 0\n",
    "    for i in range(len(weights)):\n",
    "        imputed_val += weights[i] * values[i]\n",
    "#         print(imputed_val)\n",
    "        \n",
    "    return imputed_val         \n",
    "\n",
    "def predict_feature_mean(row, C, k, originalArr,ft_idx):\n",
    "    \n",
    "    distances = []\n",
    "    for i in range(len(C)):\n",
    "        distances.append(distance(row,C[i]))\n",
    "    distances = np.array(distances)\n",
    "        \n",
    "    idx = np.argpartition(distances, k)\n",
    "#     print(idx)\n",
    "    \n",
    "    values = []\n",
    "    min_dists = []\n",
    "    for i in range(k):\n",
    "        values.append(originalArr[idx[i]][ft_idx])\n",
    "#         print(Z[idx[i]])\n",
    "        min_dists.append(distances[idx[i]])\n",
    "    values = np.array(values) \n",
    "    min_dists = np.array(min_dists)\n",
    "    \n",
    "#     print(values)\n",
    "        \n",
    "    imputed_val = 0\n",
    "    for i in range(len(values)):\n",
    "        imputed_val += values[i]/(len(values))\n",
    "#         print(imputed_val)\n",
    "        \n",
    "    return imputed_val          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "14\n",
      "\n",
      "\n",
      "17\n",
      "\n",
      "\n",
      "18\n",
      "\n",
      "\n",
      "19\n",
      "\n",
      "\n",
      "20\n",
      "\n",
      "\n",
      "21\n",
      "\n",
      "\n",
      "22\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict using k neighbors\n",
    "\n",
    "imputed_8_Y = np.copy(Y)\n",
    "# imputed_8_Y_std = np.copy(Y_std)\n",
    "\n",
    "k = 5\n",
    "\n",
    "cols_with_8 = [1,8,14,17,18,19,20,21,22]\n",
    "\n",
    "for q in cols_with_8:\n",
    "\n",
    "    print(q)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    for i in range(samples):\n",
    "\n",
    "        if Y[i][q] == -8:\n",
    "\n",
    "#             print(Y[i])\n",
    "\n",
    "            row_to_comp = []\n",
    "            mask = []\n",
    "            scaled = scaled_row(Y[i])\n",
    "            for j in range(features):\n",
    "                if Y[i][j] >= 0:\n",
    "                    mask.append(1)\n",
    "                    row_to_comp.append(scaled[j])\n",
    "                else:\n",
    "                    mask.append(0)\n",
    "            row_to_comp = np.array(row_to_comp)\n",
    "            mask = np.array(mask)\n",
    "\n",
    "            S = masked_arr(Z_std, mask)\n",
    "\n",
    "    #         print(row_to_comp.shape)\n",
    "    #         print(S.shape)\n",
    "\n",
    "    #         print(row_to_comp)\n",
    "    #         print(S)\n",
    "\n",
    "            imputed = predict_feature_mean(row_to_comp, S, k, Z_std, q)\n",
    "#             print(imputed)\n",
    "#             print(imputed*scaler.scale_[q] + scaler.mean_[q])\n",
    "\n",
    "            imputed_8_Y[i][q] = imputed*scaler.scale_[q] + scaler.mean_[q]\n",
    "            if imputed_8_Y[i][q]<0:\n",
    "                print(i)\n",
    "                print(Y[i])\n",
    "                print(imputed_8_Y[i][q])\n",
    "                while True:\n",
    "                    a =1\n",
    "    #         imputed_8_Z_std[i][1] = imputed\n",
    "\n",
    "#             print(imputed_8_Y[i])\n",
    "    #         print(imputed_8_Z_std[i])\n",
    "    \n",
    "#             print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_8 = pd.DataFrame(imputed_8_Y)\n",
    "df_8.to_csv(\"dataset_fix_8.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9 17 17 17 1 0 0 100 -7 9 8 1 0 100 0 0 0 69.599999999999994\n",
      " 75.599999999999994 2.3999999999999999 3.0 1.0 93.200000000000003]\n",
      "[-9 24 24 24 1 3 3 100 -7 0 8 1 0 100 3 1 1 32.200000000000003\n",
      " 61.399999999999999 0.99999999999999956 2.7999999999999998 0.0\n",
      " 88.400000000000006]\n",
      "[-9 92 82 87 2 0 0 100 -7 9 8 2 0 50 -7 0 0 65.200000000000003\n",
      " 34.799999999999997 5.0 1.8 2.8000000000000003 81.0]\n",
      "[-9 87 10 35 18 1 1 89 3 2 4 19 2 16 0 2 2 29 73 6 1 1 47]\n",
      "[-9 115 55 78 3 0 0 100 -7 9 8 3 0 100 0 0 0 68.0 25.399999999999999\n",
      " 3.3999999999999999 2.2000000000000002 1.8 78.799999999999997]\n",
      "[-9 173 2 59 74 3 3 99 8 0 2 77 9 25 0 10 9 22 97 7 4 4 62]\n",
      "[-9 175 159 167 2 1 1 100 -7 9 8 3 0 50 0 2 2 54.799999999999997\n",
      " 36.400000000000006 5.4000000000000004 1.8 2.8000000000000003\n",
      " 82.200000000000003]\n",
      "[-9 383 383 383 1 1 1 100 -7 6 8 1 0 100 -7 1 1 54.799999999999997\n",
      " 36.400000000000006 5.4000000000000004 1.8 2.8000000000000003\n",
      " 82.200000000000003]\n",
      "[-9 297 6 93 18 0 0 95 16 6 6 20 2 55 0 0 0 10 96 1 1 0 33]\n",
      "[-9 85 28 179 3 5 5 50 15 6 4 4 0 0 2 3 3 79.200000000000003\n",
      " 61.399999999999999 3.0 2.0 0.59999999999999998 86.799999999999997]\n"
     ]
    }
   ],
   "source": [
    "for i in imputed_8_Y:\n",
    "    for j in i:\n",
    "        if j == -9:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
