{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "import numpy.polynomial.polynomial as poly\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "import copy\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"xML Challenge Dataset and Data Dictionary/heloc_dataset_v1.csv\")\n",
    "feature_names = list(df)\n",
    "data = df.values\n",
    "\n",
    "y_original= data[:,:1]\n",
    "X_original = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# --- Basic Functions for Matrix editing --- \n",
    "\n",
    "def remove_row_with_all_same_val(data, target, val):\n",
    "    row_no = 0 \n",
    "    for row in data:\n",
    "        for col in row:\n",
    "            if (col == val):\n",
    "                remove = True\n",
    "            else:\n",
    "                remove = False\n",
    "                break\n",
    "\n",
    "        if remove:\n",
    "            data = np.delete(data, row_no, 0)\n",
    "            target = np.delete(target, row_no, 0)     \n",
    "\n",
    "        else:\n",
    "            row_no += 1\n",
    "    return data,target\n",
    "\n",
    "def remove_row_with_vals(data, target, vals):\n",
    "    row_no = 0 \n",
    "    for row in data:\n",
    "        for col in row:\n",
    "            if (col in vals):\n",
    "                data = np.delete(data, row_no, 0)\n",
    "                target = np.delete(target, row_no, 0) \n",
    "                row_no -= 1\n",
    "                break\n",
    "        row_no += 1\n",
    "    return data,target\n",
    "\n",
    "\n",
    "def remove_col_with_vals(data, vals):\n",
    "    no_cols = data.shape[1]\n",
    "    no_rows = data.shape[0]\n",
    "    row = 0\n",
    "    while (no_rows > row):\n",
    "        col = 0\n",
    "        while (no_cols > col):\n",
    "            if (data[row][col] in vals):\n",
    "                data = np.delete(data, col, 1)\n",
    "                no_cols -= 1\n",
    "            else:\n",
    "                col += 1\n",
    "        row += 1     \n",
    "    return data\n",
    "\n",
    "\n",
    "def scaled_row(row):\n",
    "    scld = []\n",
    "    for k in range(features):\n",
    "        scld.append((row[k] - scaler.mean_[k])/scaler.scale_[k])\n",
    "    scld = np.array(scld)\n",
    "    return scld\n",
    "        \n",
    "        \n",
    "def masked_arr(A, mask):\n",
    "    B = []\n",
    "    for i in range(len(A)):\n",
    "        row = []\n",
    "        for j in range(len(A[0])):\n",
    "            if mask[j] != 0:\n",
    "                row.append(A[i][j])\n",
    "        B.append(row)\n",
    "    B = np.array(B)\n",
    "    return B\n",
    "\n",
    "def distance(row1, row2):\n",
    "    dist = 0\n",
    "    for i in range(len(row1)):\n",
    "        t = (row1[i]-row2[i])**2\n",
    "        dist += t\n",
    "    dist = np.sqrt(dist)\n",
    "    return dist\n",
    "\n",
    "# predict features using kNN imputation\n",
    "# need to test for both weighted and simple mean\n",
    "# using 3 or 5 neighbors\n",
    "def predict_feature_weighted(row, C, k, originalArr, ft_idx):\n",
    "    \n",
    "    distances = []\n",
    "    for i in range(len(C)):\n",
    "        distances.append(distance(row,C[i]))\n",
    "    distances = np.array(distances)\n",
    "    \n",
    "    max_dist = np.max(distances)\n",
    "        \n",
    "    idx = np.argpartition(distances, k)\n",
    "#     print(idx)\n",
    "    \n",
    "    values = []\n",
    "    min_dists = []\n",
    "    for i in range(k):\n",
    "        values.append(originalArr[idx[i]][ft_idx])\n",
    "#         print(Z[idx[i]])\n",
    "        min_dists.append(distances[idx[i]])\n",
    "    values = np.array(values) \n",
    "    min_dists = np.array(min_dists)\n",
    "    \n",
    "#     max_dist = np.max(min_dists)\n",
    "\n",
    "    weights = []\n",
    "    for i in min_dists:\n",
    "        weights.append(1 - (i/max_dist))\n",
    "    \n",
    "#     print(weights)\n",
    "#     print(values)\n",
    "        \n",
    "    imputed_val = 0\n",
    "    for i in range(len(weights)):\n",
    "        imputed_val += weights[i] * values[i]\n",
    "#         print(imputed_val)\n",
    "        \n",
    "    return imputed_val         \n",
    "\n",
    "def predict_feature_mean(row, C, k, originalArr,ft_idx):\n",
    "    \n",
    "    distances = []\n",
    "    for i in range(len(C)):\n",
    "        distances.append(distance(row,C[i]))\n",
    "    distances = np.array(distances)\n",
    "        \n",
    "    idx = np.argpartition(distances, k)\n",
    "#     print(idx)\n",
    "    \n",
    "    values = []\n",
    "    min_dists = []\n",
    "    for i in range(k):\n",
    "        values.append(originalArr[idx[i]][ft_idx])\n",
    "#         print(Z[idx[i]])\n",
    "        min_dists.append(distances[idx[i]])\n",
    "    values = np.array(values) \n",
    "    min_dists = np.array(min_dists)\n",
    "    \n",
    "#     print(values)\n",
    "        \n",
    "    imputed_val = 0\n",
    "    for i in range(len(values)):\n",
    "        imputed_val += values[i]/(len(values))\n",
    "#         print(imputed_val)\n",
    "        \n",
    "    return imputed_val          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10459, 23)\n",
      "(9871, 23)\n",
      "(10459, 1)\n",
      "(9871, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Removing the rows with only -9 values ---\n",
    "X, y = remove_row_with_all_same_val(X_original,y_original,-9)\n",
    "\n",
    "# --- Testing ---\n",
    "print(X_original.shape)\n",
    "print(X.shape)\n",
    "print(y_original.shape)\n",
    "print(y.shape)\n",
    "\n",
    "Y = np.copy(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Taking the array without any negatives present ---\n",
    "\n",
    "samples, features = Y.shape\n",
    "\n",
    "Z = []\n",
    "\n",
    "for i in range(samples):\n",
    "    remove = False\n",
    "    for j in range(features):\n",
    "        if Y[i][j] < 0:\n",
    "            remove = True\n",
    "            break\n",
    "    if remove == False:\n",
    "        Z.append(Y[i])\n",
    "        \n",
    "Z = np.array(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/steffen/anaconda/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "8\n",
      "\n",
      "\n",
      "14\n",
      "\n",
      "\n",
      "17\n",
      "\n",
      "\n",
      "18\n",
      "\n",
      "\n",
      "19\n",
      "\n",
      "\n",
      "20\n",
      "\n",
      "\n",
      "21\n",
      "\n",
      "\n",
      "22\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Replacing -8 with k-nearest neighbours (average) ---\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Z_std = scaler.fit_transform(Z)\n",
    "\n",
    "imputed_8_Y = np.copy(Y)\n",
    "# imputed_8_Y_std = np.copy(Y_std)\n",
    "\n",
    "k = 5\n",
    "\n",
    "cols_with_8 = [1,8,14,17,18,19,20,21,22]\n",
    "\n",
    "for q in cols_with_8:\n",
    "\n",
    "    print(q)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    for i in range(samples):\n",
    "\n",
    "        if Y[i][q] == -8:\n",
    "\n",
    "#             print(Y[i])\n",
    "\n",
    "            row_to_comp = []\n",
    "            mask = []\n",
    "            scaled = scaled_row(Y[i])\n",
    "            for j in range(features):\n",
    "                if Y[i][j] >= 0:\n",
    "                    mask.append(1)\n",
    "                    row_to_comp.append(scaled[j])\n",
    "                else:\n",
    "                    mask.append(0)\n",
    "            row_to_comp = np.array(row_to_comp)\n",
    "            mask = np.array(mask)\n",
    "\n",
    "            S = masked_arr(Z_std, mask)\n",
    "\n",
    "    #         print(row_to_comp.shape)\n",
    "    #         print(S.shape)\n",
    "\n",
    "    #         print(row_to_comp)\n",
    "    #         print(S)\n",
    "\n",
    "            imputed = predict_feature_mean(row_to_comp, S, k, Z_std, q)\n",
    "#             print(imputed)\n",
    "#             print(imputed*scaler.scale_[q] + scaler.mean_[q])\n",
    "\n",
    "            imputed_8_Y[i][q] = imputed*scaler.scale_[q] + scaler.mean_[q]\n",
    "            if imputed_8_Y[i][q]<0:\n",
    "                print(i)\n",
    "                print(Y[i])\n",
    "                print(imputed_8_Y[i][q])\n",
    "                while True:\n",
    "                    a =1\n",
    "    #         imputed_8_Z_std[i][1] = imputed\n",
    "\n",
    "#             print(imputed_8_Y[i])\n",
    "    #         print(imputed_8_Z_std[i])\n",
    "    \n",
    "#             print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_no8 = np.copy(imputed_8_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55]\n",
      " [61]\n",
      " [67]\n",
      " ..., \n",
      " [74]\n",
      " [72]\n",
      " [66]]\n"
     ]
    }
   ],
   "source": [
    "# --- Selecting the column with -9  ---\n",
    "y_nine = X_no8[:,:1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --- Selecting the columns with -7  ---\n",
    "X_no8 = np.copy(imputed_8_Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # --- Removing the columns that have -8 values ---\n",
    "# X2 = remove_col_with_vals(X,[-8])\n",
    "\n",
    "# # --- Testing ---\n",
    "# print(X.shape)\n",
    "# print(X2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model_degrees(X_tr,y_tr,degrees):\n",
    "    RSS_list = []\n",
    "    for deg in degrees:\n",
    "        model = poly.polyfit(X_tr,y_tr,degree)\n",
    "        pred = poly.polyval(X_tr, model)\n",
    "        RSS = np.mean((Y_tr-pred)**2)\n",
    "        RSS_list.append(RSS)\n",
    "        \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(degrees,RSS_list,'.-',color='r') \n",
    "    plt.xlabel('Degree')                            \n",
    "    plt.ylabel('Performance')\n",
    "    \n",
    "\n",
    "def predict_values_poly_reg(X_tr,y_tr,X_test,deg):\n",
    "    model = poly.polyfit(X_tr,y_tr,degree)\n",
    "    pred = poly.polyval(X_test, model)\n",
    "    return pred\n",
    "\n",
    "def predict_values_lin_reg(X_tr,y_tr,X_test):\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_tr, y_tr)\n",
    "    pred = model.predict(X_test)\n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
